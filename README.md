# Text_To_Image_Using_Stable_Diffusion

Diffusers: https://huggingface.co/docs/diffusers/index

Diffusion Pipeline makes it possible to use diffusion systems with easy to use API.

Primary components of the diffusion pipeline: UNet model and schedulers

UNet model: takes a random noise to generate the noise residual
Scheduler: uses the noise residual to generate a less noisy image 

Pipelines such as Stable diffusion, use additional component (tokenizers) to convert the prompt to embeddings

Tokenizer: Tokenization involves breaking down a piece of text into smaller units, which are usually words or subwords. 
This process is crucial for various natural language processing (NLP) tasks, such as text analysis, language modeling, 
and machine translation.

Transformers provide pre-built tokenizers for various languages and tasks. 
These tokenizers are often customizable and efficient for use in NLP pipelines.

Inference: Inference refers to the process of using a trained model to make predictions or decisions based on new, unseen data.

Embeddings(generated by Transformers): Embeddings are numerical representations of real-world objects that machine learning (ML) and artificial intelligence (AI) 
systems use to understand complex knowledge domains like humans do.

## How the text to image work (Step by Step):

1. Tokenizer convert the text prompt into an embedding 
2. The diffusion pipeline convert that embedding into an image output



## Code explanation:

#We are using the model stable-diffusion-xl-base-1.0

model_id1 = "stabilityai/stable-diffusion-xl-base-1.0"

#To save GPU memory and get more speed use float16

pipe = StableDiffusionPipeline.from_pretrained(model_id1, torch_dtype=torch.float16)

#we use cuda to be able to use the GPU for processing

pipe = pipe.to("cuda")

#Write your prompts. The more context is given in the prompt, the more accurate the image will be generated.

prompt = """dreamlikeart, a grungy woman with rainbow hair, travelling between dimensions, dynamic pose, happy, soft eyes and narrow chin,
extreme bokeh, dainty figure, long hair straight down, torn kawaii shirt and baggy jeans
"""

#multiple images are generated and we choose the best one

image = pipe(prompt).images[0]

#print out image generated

print("[PROMPT]: ",prompt)
plt.imshow(image);
plt.axis('off');


## Image generated

![image](https://github.com/mervinsumboo/Text_To_Image_Using_Stable_Diffusion/assets/61121862/13c8e8d4-f01c-41ba-baa4-4d1636e52908)
